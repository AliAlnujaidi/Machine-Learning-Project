{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6VUkzeKywAQBFF1kIUoFc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3GEnk869RNC",
        "outputId": "7259e54a-b4b9-48c4-a8c6-38f86ddc4b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 39 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 47.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=dc8ddab82056ef247dde09f41925632ad06720a53e4ae6191f8733c5bf9f0486\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import *\n",
        "\n",
        "spark= SparkSession.builder\\\n",
        ".master(\"local\")\\\n",
        ".appName(\"Colab\")\\\n",
        ".config('spark.ui.port', '4050')\\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3if5x_i9ckG",
        "outputId": "bf50ef49-2692-484d-b794-72bb7399ac65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (7.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imUhwCPg9d1y",
        "outputId": "865f186c-d003-422c-af86-c5d148eef922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import col\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from  pyspark import pandas"
      ],
      "metadata": {
        "id": "vWE53SDa9fOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e2fa8b-d1f5-47e3-b1db-4aebb37cf201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/phamtheds/predict-flight-delays?select=Predict_Flight_Delays_2022_M1_M4.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdPHwo_D9jLS",
        "outputId": "141004b4-cb1f-4d83-9789-3c59e980a9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: alialnujaidi\n",
            "Your Kaggle Key: ··········\n",
            "Downloading predict-flight-delays.zip to ./predict-flight-delays\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 842M/842M [00:10<00:00, 82.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "alialnujaidi\n",
        "\n",
        "3b1e0a628c830e978368ab04b89840b1"
      ],
      "metadata": {
        "id": "hP3LQXKtXBad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"predict-flight-delays/Predict_Flight_Delays_2022_M1_M4.csv\")"
      ],
      "metadata": {
        "id": "4jJ0q2DO9lH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('DEP_TIME','DEP_DELAY','AIR_TIME','DISTANCE').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-5mV_tMaUZ3",
        "outputId": "f41554fd-5f31-4b28-8c4d-ea9e483c242c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+--------+--------+\n",
            "|DEP_TIME|DEP_DELAY|AIR_TIME|DISTANCE|\n",
            "+--------+---------+--------+--------+\n",
            "|  1221.0|     -3.0|    63.0|   323.0|\n",
            "|  1214.0|    -10.0|    50.0|   323.0|\n",
            "|  1218.0|     -6.0|    53.0|   323.0|\n",
            "|  1217.0|     -7.0|    56.0|   323.0|\n",
            "|  1218.0|     -6.0|    48.0|   323.0|\n",
            "|  1219.0|     -5.0|    49.0|   323.0|\n",
            "|  1217.0|     -7.0|    58.0|   323.0|\n",
            "|  1220.0|     -4.0|    49.0|   323.0|\n",
            "|  1220.0|     -4.0|    52.0|   323.0|\n",
            "|  1223.0|     -1.0|    49.0|   323.0|\n",
            "|  1218.0|     -6.0|    53.0|   323.0|\n",
            "|  1224.0|      0.0|    59.0|   323.0|\n",
            "|  1224.0|      0.0|    57.0|   323.0|\n",
            "|  1213.0|    -11.0|    52.0|   323.0|\n",
            "|  1217.0|     -7.0|    60.0|   323.0|\n",
            "|  1222.0|     -2.0|    56.0|   323.0|\n",
            "|  1220.0|     -4.0|    50.0|   323.0|\n",
            "|  1223.0|     -1.0|    59.0|   323.0|\n",
            "|  1008.0|     -2.0|    64.0|   323.0|\n",
            "|  1007.0|     -3.0|    59.0|   323.0|\n",
            "+--------+---------+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`PreProcessing`**:\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TPys_MHlberc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"DEP_TIME\",col(\"DEP_TIME\").cast(\"double\")).dropna(\"any\")\n",
        "df = df.withColumn(\"DEP_DELAY\",col(\"DEP_DELAY\").cast(\"double\")).dropna(\"any\")\n",
        "df = df.withColumn(\"AIR_TIME\",col(\"AIR_TIME\").cast(\"double\")).dropna(\"any\")\n",
        "df = df.withColumn(\"DISTANCE\",col(\"DISTANCE\").cast(\"double\")).dropna(\"any\")"
      ],
      "metadata": {
        "id": "9hfWYBHfbeAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uHN52QFyeo1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vector\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "input_cols = ['DEP_TIME','DISTANCE','AIR_TIME']\n",
        "assembler = VectorAssembler(inputCols=input_cols, outputCol='features')\n",
        "df = assembler.transform(df)"
      ],
      "metadata": {
        "id": "2Ad2FtWkZtV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select(\"features\",\"DEP_DELAY\")"
      ],
      "metadata": {
        "id": "liatQf_wo1JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, test_data) = df.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "7qhe2CNKcxGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "_Hkdep4YeORO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "metadata": {
        "id": "neZEq1Be_yZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression(labelCol = \"DEP_DELAY\")"
      ],
      "metadata": {
        "id": "S6uZAywXeVMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = reg.fit(train_data)"
      ],
      "metadata": {
        "id": "9vBHOjMxedK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "-8OA3UJegAc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_data = test_data.select(\"features\")"
      ],
      "metadata": {
        "id": "O-jfItDnguBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(unlabeled_data)"
      ],
      "metadata": {
        "id": "iOkziDOuA_ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoG8yuPiy15j",
        "outputId": "5b0411c3-a8d7-4e7c-9c34-55e12174399e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------------+\n",
            "|         features|         prediction|\n",
            "+-----------------+-------------------+\n",
            "| [1.0,150.0,32.0]|-5.2567932199345355|\n",
            "| [1.0,152.0,28.0]| -5.278999231410023|\n",
            "| [1.0,351.0,53.0]| -4.843497116322919|\n",
            "| [1.0,391.0,58.0]|  -4.75611611217702|\n",
            "|[1.0,888.0,108.0]| -3.746224223406286|\n",
            "+-----------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MAE Reg model: \", res.meanAbsoluteError)\n",
        "print(\"MSE Reg model: \", res.meanSquaredError)\n",
        "print(\"RMSE Reg model: \", res.rootMeanSquaredError)\n",
        "print(\"R2 Reg model:\", res.r2)\n",
        "print(\"Adj R2 Reg model:\", res.r2adj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TsJ3su6hmzq",
        "outputId": "fbc4a81a-bd84-43e8-c503-65a3e151493a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE Reg model:  22.243838985084892\n",
            "MSE Reg model:  2637.0922212583196\n",
            "RMSE Reg model:  51.35262623526006\n",
            "R2 Reg model: 0.013693216594809154\n",
            "Adj R2 Reg model: 0.013688456013371542\n"
          ]
        }
      ]
    }
  ]
}